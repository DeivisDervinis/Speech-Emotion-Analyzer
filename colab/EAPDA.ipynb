{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    },
    "colab": {
      "name": "EAPDA.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeivisDervinis/EAPDA/blob/main/colab/EAPDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TX-hk1ZKy8-"
      },
      "source": [
        "# Step 1. Install required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krDhb498o2Jo",
        "outputId": "6be3add3-b010-4aa6-b7bd-f920193b4209"
      },
      "source": [
        "!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg\n",
        "!pip install PyAudio\n",
        "!pip install pydub"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libportaudio2 is already the newest version (19.6.0-1).\n",
            "libportaudiocpp0 is already the newest version (19.6.0-1).\n",
            "portaudio19-dev is already the newest version (19.6.0-1).\n",
            "libasound2-dev is already the newest version (1.1.3-5ubuntu0.5).\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n",
            "Requirement already satisfied: PyAudio in /usr/local/lib/python3.7/dist-packages (0.2.11)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.7/dist-packages (0.25.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocXbPKOdK-yQ"
      },
      "source": [
        "# Step 2. Create models folder and download the latest emotion recognition model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bcc3P4b_q2Xe",
        "outputId": "24c5bded-337c-41e4-96f2-91e25236c735"
      },
      "source": [
        "!mkdir models\n",
        "!mkdir working\n",
        "!wget http://github.com/DeivisDervinis/EAPDA/raw/main/colab/models/audio.hdf5 -O models/audio.hdf5\n",
        "!wget http://github.com/DeivisDervinis/EAPDA/raw/main/colab/models/testfile.json -O models/testfile.json\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘models’: File exists\n",
            "mkdir: cannot create directory ‘working’: File exists\n",
            "URL transformed to HTTPS due to an HSTS policy\n",
            "--2021-03-12 18:48:57--  https://github.com/DeivisDervinis/EAPDA/raw/main/colab/models/audio.hdf5\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/DeivisDervinis/EAPDA/main/colab/models/audio.hdf5 [following]\n",
            "--2021-03-12 18:48:57--  https://raw.githubusercontent.com/DeivisDervinis/EAPDA/main/colab/models/audio.hdf5\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5368560 (5.1M) [application/octet-stream]\n",
            "Saving to: ‘models/audio.hdf5’\n",
            "\n",
            "models/audio.hdf5   100%[===================>]   5.12M  28.1MB/s    in 0.2s    \n",
            "\n",
            "2021-03-12 18:49:03 (28.1 MB/s) - ‘models/audio.hdf5’ saved [5368560/5368560]\n",
            "\n",
            "URL transformed to HTTPS due to an HSTS policy\n",
            "--2021-03-12 18:49:04--  https://github.com/DeivisDervinis/EAPDA/raw/main/colab/models/testfile.json\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/DeivisDervinis/EAPDA/main/colab/models/testfile.json [following]\n",
            "--2021-03-12 18:49:04--  https://raw.githubusercontent.com/DeivisDervinis/EAPDA/main/colab/models/testfile.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 336 [text/plain]\n",
            "Saving to: ‘models/testfile.json’\n",
            "\n",
            "models/testfile.jso 100%[===================>]     336  --.-KB/s    in 0s      \n",
            "\n",
            "2021-03-12 18:49:07 (15.8 MB/s) - ‘models/testfile.json’ saved [336/336]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "Fn0itlx7dCld",
        "outputId": "a6669288-bb33-461b-ba8a-5e082bf48a7b"
      },
      "source": [
        "from google.colab import files\r\n",
        "\r\n",
        "uploaded = files.upload()\r\n",
        "\r\n",
        "for fn in uploaded.keys():\r\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\r\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b8e8f07f-4a33-41dc-81f4-a1a06c5943e3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b8e8f07f-4a33-41dc-81f4-a1a06c5943e3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving joined_sound_7 .wav to joined_sound_7  (1).wav\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QksFjwy8LHK9"
      },
      "source": [
        "# Step 3. Download audio files for Emotion Recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62VZGuVAqka0",
        "outputId": "7ca21cf2-1be2-408f-d50f-77d22225d4ac"
      },
      "source": [
        "!mkdir data\n",
        "!wget http://github.com/DeivisDervinis/EAPDA/raw/main/colab/data/joined_sound_1.wav -O data/joined_sound_1.wav\n",
        "!wget http://github.com/DeivisDervinis/EAPDA/raw/main/colab/data/joined_sound_2.wav -O data/joined_sound_2.wav\n",
        "!wget http://github.com/DeivisDervinis/EAPDA/raw/main/colab/data/joined_sound_3.wav -O data/joined_sound_3.wav\n",
        "!wget http://github.com/DeivisDervinis/EAPDA/raw/main/colab/data/joined_sound_4.wav -O data/joined_sound_4.wav\n",
        "!wget http://github.com/DeivisDervinis/EAPDA/raw/main/colab/data/joined_sound_5.wav -O data/joined_sound_5.wav\n",
        "!wget http://github.com/DeivisDervinis/EAPDA/raw/main/colab/data/joined_sound_6.wav -O data/joined_sound_6.wav\n",
        "!wget http://github.com/DeivisDervinis/EAPDA/raw/main/colab/data/joined_sound_7.wav -O data/joined_sound_7.wav\n",
        "!wget http://github.com/DeivisDervinis/EAPDA/raw/main/colab/data/joined_sound_8.wav -O data/joined_sound_8.wav\n",
        "!wget http://github.com/DeivisDervinis/EAPDA/raw/main/colab/data/joined_sound_9.wav -O data/joined_sound_9.wav"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n",
            "URL transformed to HTTPS due to an HSTS policy\n",
            "--2021-03-12 19:08:28--  https://github.com/DeivisDervinis/EAPDA/raw/main/colab/data/joined_sound_1.wav\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/DeivisDervinis/EAPDA/main/colab/data/joined_sound_1.wav [following]\n",
            "--2021-03-12 19:08:28--  https://raw.githubusercontent.com/DeivisDervinis/EAPDA/main/colab/data/joined_sound_1.wav\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1396444 (1.3M) [audio/wav]\n",
            "Saving to: ‘data/joined_sound_1.wav’\n",
            "\n",
            "data/joined_sound_1 100%[===================>]   1.33M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2021-03-12 19:08:29 (19.2 MB/s) - ‘data/joined_sound_1.wav’ saved [1396444/1396444]\n",
            "\n",
            "URL transformed to HTTPS due to an HSTS policy\n",
            "--2021-03-12 19:08:29--  https://github.com/DeivisDervinis/EAPDA/raw/main/colab/data/joined_sound_2.wav\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/DeivisDervinis/EAPDA/main/colab/data/joined_sound_2.wav [following]\n",
            "--2021-03-12 19:08:29--  https://raw.githubusercontent.com/DeivisDervinis/EAPDA/main/colab/data/joined_sound_2.wav\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1546970 (1.5M) [audio/wav]\n",
            "Saving to: ‘data/joined_sound_2.wav’\n",
            "\n",
            "data/joined_sound_2 100%[===================>]   1.47M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2021-03-12 19:08:29 (20.1 MB/s) - ‘data/joined_sound_2.wav’ saved [1546970/1546970]\n",
            "\n",
            "URL transformed to HTTPS due to an HSTS policy\n",
            "--2021-03-12 19:08:29--  https://github.com/DeivisDervinis/EAPDA/raw/main/colab/data/joined_sound_3.wav\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/DeivisDervinis/EAPDA/main/colab/data/joined_sound_3.wav [following]\n",
            "--2021-03-12 19:08:30--  https://raw.githubusercontent.com/DeivisDervinis/EAPDA/main/colab/data/joined_sound_3.wav\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1503310 (1.4M) [audio/wav]\n",
            "Saving to: ‘data/joined_sound_3.wav’\n",
            "\n",
            "data/joined_sound_3 100%[===================>]   1.43M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2021-03-12 19:08:30 (19.4 MB/s) - ‘data/joined_sound_3.wav’ saved [1503310/1503310]\n",
            "\n",
            "URL transformed to HTTPS due to an HSTS policy\n",
            "--2021-03-12 19:08:30--  https://github.com/DeivisDervinis/EAPDA/raw/main/colab/data/joined_sound_4.wav\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/DeivisDervinis/EAPDA/main/colab/data/joined_sound_4.wav [following]\n",
            "--2021-03-12 19:08:30--  https://raw.githubusercontent.com/DeivisDervinis/EAPDA/main/colab/data/joined_sound_4.wav\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2035790 (1.9M) [audio/wav]\n",
            "Saving to: ‘data/joined_sound_4.wav’\n",
            "\n",
            "data/joined_sound_4 100%[===================>]   1.94M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2021-03-12 19:08:31 (21.6 MB/s) - ‘data/joined_sound_4.wav’ saved [2035790/2035790]\n",
            "\n",
            "URL transformed to HTTPS due to an HSTS policy\n",
            "--2021-03-12 19:08:31--  https://github.com/DeivisDervinis/EAPDA/raw/main/colab/data/joined_sound_5.wav\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/DeivisDervinis/EAPDA/main/colab/data/joined_sound_5.wav [following]\n",
            "--2021-03-12 19:08:31--  https://raw.githubusercontent.com/DeivisDervinis/EAPDA/main/colab/data/joined_sound_5.wav\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2015310 (1.9M) [audio/wav]\n",
            "Saving to: ‘data/joined_sound_5.wav’\n",
            "\n",
            "data/joined_sound_5 100%[===================>]   1.92M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2021-03-12 19:08:32 (21.3 MB/s) - ‘data/joined_sound_5.wav’ saved [2015310/2015310]\n",
            "\n",
            "URL transformed to HTTPS due to an HSTS policy\n",
            "--2021-03-12 19:08:32--  https://github.com/DeivisDervinis/EAPDA/raw/main/colab/data/joined_sound_6.wav\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/DeivisDervinis/EAPDA/main/colab/data/joined_sound_6.wav [following]\n",
            "--2021-03-12 19:08:32--  https://raw.githubusercontent.com/DeivisDervinis/EAPDA/main/colab/data/joined_sound_6.wav\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1168358 (1.1M) [audio/wav]\n",
            "Saving to: ‘data/joined_sound_6.wav’\n",
            "\n",
            "data/joined_sound_6 100%[===================>]   1.11M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2021-03-12 19:08:32 (16.9 MB/s) - ‘data/joined_sound_6.wav’ saved [1168358/1168358]\n",
            "\n",
            "URL transformed to HTTPS due to an HSTS policy\n",
            "--2021-03-12 19:08:32--  https://github.com/DeivisDervinis/EAPDA/raw/main/colab/data/joined_sound_7.wav\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/DeivisDervinis/EAPDA/main/colab/data/joined_sound_7.wav [following]\n",
            "--2021-03-12 19:08:33--  https://raw.githubusercontent.com/DeivisDervinis/EAPDA/main/colab/data/joined_sound_7.wav\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6764622 (6.5M) [application/octet-stream]\n",
            "Saving to: ‘data/joined_sound_7.wav’\n",
            "\n",
            "data/joined_sound_7 100%[===================>]   6.45M  33.0MB/s    in 0.2s    \n",
            "\n",
            "2021-03-12 19:08:33 (33.0 MB/s) - ‘data/joined_sound_7.wav’ saved [6764622/6764622]\n",
            "\n",
            "URL transformed to HTTPS due to an HSTS policy\n",
            "--2021-03-12 19:08:33--  https://github.com/DeivisDervinis/EAPDA/raw/main/colab/data/joined_sound_8.wav\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/DeivisDervinis/EAPDA/main/colab/data/joined_sound_8.wav [following]\n",
            "--2021-03-12 19:08:34--  https://raw.githubusercontent.com/DeivisDervinis/EAPDA/main/colab/data/joined_sound_8.wav\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6973488 (6.7M) [application/octet-stream]\n",
            "Saving to: ‘data/joined_sound_8.wav’\n",
            "\n",
            "data/joined_sound_8 100%[===================>]   6.65M  31.1MB/s    in 0.2s    \n",
            "\n",
            "2021-03-12 19:08:34 (31.1 MB/s) - ‘data/joined_sound_8.wav’ saved [6973488/6973488]\n",
            "\n",
            "URL transformed to HTTPS due to an HSTS policy\n",
            "--2021-03-12 19:08:34--  https://github.com/DeivisDervinis/EAPDA/raw/main/colab/data/joined_sound_9.wav\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/DeivisDervinis/EAPDA/main/colab/data/joined_sound_9.wav [following]\n",
            "--2021-03-12 19:08:34--  https://raw.githubusercontent.com/DeivisDervinis/EAPDA/main/colab/data/joined_sound_9.wav\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15918140 (15M) [application/octet-stream]\n",
            "Saving to: ‘data/joined_sound_9.wav’\n",
            "\n",
            "data/joined_sound_9 100%[===================>]  15.18M  44.3MB/s    in 0.3s    \n",
            "\n",
            "2021-03-12 19:08:35 (44.3 MB/s) - ‘data/joined_sound_9.wav’ saved [15918140/15918140]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j08pOw9UNOzq"
      },
      "source": [
        "# Step 4. Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_Kuqv-inYtx"
      },
      "source": [
        "## Basics ##\n",
        "import time\n",
        "import os\n",
        "import numpy as np\n",
        "## Audio Preprocessing ##\n",
        "import pyaudio\n",
        "import wave\n",
        "import librosa\n",
        "from scipy.stats import zscore\n",
        "\n",
        "## Time Distributed CNN ##\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, TimeDistributed\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Flatten\n",
        "from tensorflow.keras.layers import LSTM"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKhTchpvNWfv"
      },
      "source": [
        "# Step 5. Load code for Emotion Recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QA-VJtVnYt2"
      },
      "source": [
        "class speechEmotionRecognition:\n",
        "\n",
        "    ###\n",
        "    ##Voice recording function\n",
        "    ##\n",
        "\n",
        "    def __init__(self, subdir_model=None):\n",
        "\n",
        "        # Load prediction model\n",
        "        if subdir_model is not None:\n",
        "            self._model = self.build_model()\n",
        "            self._model.load_weights(subdir_model)\n",
        "\n",
        "        # Emotion encoding\n",
        "        self._emotion = {0:'Angry', 1:'Disgust', 2:'Fear', 3:'Happy', 4:'Neutral', 5:'Sad', 6:'Surprise'}\n",
        "\n",
        "\n",
        "    ### Computing Mel-Spectrogram\n",
        "    def mel_spectrogram(self, y, sr=16000, n_fft=512, win_length=256, hop_length=128, window='hamming', n_mels=128, fmax=4000):\n",
        "\n",
        "        # Compute spectogram\n",
        "        mel_spect = np.abs(librosa.stft(y, n_fft=n_fft, window=window, win_length=win_length, hop_length=hop_length)) ** 2\n",
        "\n",
        "        # Compute mel spectrogram\n",
        "        mel_spect = librosa.feature.melspectrogram(S=mel_spect, sr=sr, n_mels=n_mels, fmax=fmax)\n",
        "\n",
        "        # Compute log-mel spectrogram\n",
        "        mel_spect = librosa.power_to_db(mel_spect, ref=np.max)\n",
        "\n",
        "        return np.asarray(mel_spect)\n",
        "\n",
        "\n",
        "\n",
        "    # Audio framing\n",
        "    def frame(self, y, win_step=64, win_size=128):\n",
        "\n",
        "        # Number of frames\n",
        "        nb_frames = 1 + int((y.shape[2] - win_size) / win_step)\n",
        "\n",
        "        # Framming\n",
        "        frames = np.zeros((y.shape[0], nb_frames, y.shape[1], win_size)).astype(np.float16)\n",
        "        for t in range(nb_frames):\n",
        "            frames[:,t,:,:] = np.copy(y[:,:,(t * win_step):(t * win_step + win_size)]).astype(np.float16)\n",
        "\n",
        "        return frames\n",
        "\n",
        "\n",
        "    # Builds TDCNN\n",
        "    def build_model(self):\n",
        "\n",
        "        # Clear Keras session\n",
        "        K.clear_session()\n",
        "\n",
        "        # Define input\n",
        "        input_y = Input(shape=(3, 128, 128, 1), name='Input_MELSPECT')\n",
        "\n",
        "        # First LFLB (local feature learning block)\n",
        "        y = TimeDistributed(Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same'), name='Conv_1_MELSPECT')(input_y)\n",
        "        y = TimeDistributed(BatchNormalization(), name='BatchNorm_1_MELSPECT')(y)\n",
        "        y = TimeDistributed(Activation('elu'), name='Activ_1_MELSPECT')(y)\n",
        "        y = TimeDistributed(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'), name='MaxPool_1_MELSPECT')(y)\n",
        "        y = TimeDistributed(Dropout(0.2), name='Drop_1_MELSPECT')(y)\n",
        "\n",
        "        # Second LFLB (local feature learning block)\n",
        "        y = TimeDistributed(Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same'), name='Conv_2_MELSPECT')(y)\n",
        "        y = TimeDistributed(BatchNormalization(), name='BatchNorm_2_MELSPECT')(y)\n",
        "        y = TimeDistributed(Activation('elu'), name='Activ_2_MELSPECT')(y)\n",
        "        y = TimeDistributed(MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same'), name='MaxPool_2_MELSPECT')(y)\n",
        "        y = TimeDistributed(Dropout(0.2), name='Drop_2_MELSPECT')(y)\n",
        "\n",
        "        # Third LFLB (local feature learning block)\n",
        "        y = TimeDistributed(Conv2D(128, kernel_size=(3, 3), strides=(1, 1), padding='same'), name='Conv_3_MELSPECT')(y)\n",
        "        y = TimeDistributed(BatchNormalization(), name='BatchNorm_3_MELSPECT')(y)\n",
        "        y = TimeDistributed(Activation('elu'), name='Activ_3_MELSPECT')(y)\n",
        "        y = TimeDistributed(MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same'), name='MaxPool_3_MELSPECT')(y)\n",
        "        y = TimeDistributed(Dropout(0.2), name='Drop_3_MELSPECT')(y)\n",
        "\n",
        "        # Fourth LFLB (local feature learning block)\n",
        "        y = TimeDistributed(Conv2D(128, kernel_size=(3, 3), strides=(1, 1), padding='same'), name='Conv_4_MELSPECT')(y)\n",
        "        y = TimeDistributed(BatchNormalization(), name='BatchNorm_4_MELSPECT')(y)\n",
        "        y = TimeDistributed(Activation('elu'), name='Activ_4_MELSPECT')(y)\n",
        "        y = TimeDistributed(MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same'), name='MaxPool_4_MELSPECT')(y)\n",
        "        y = TimeDistributed(Dropout(0.2), name='Drop_4_MELSPECT')(y)\n",
        "\n",
        "        # Flat\n",
        "        y = TimeDistributed(Flatten(), name='Flat_MELSPECT')(y)\n",
        "\n",
        "        # LSTM layer\n",
        "        y = LSTM(256, return_sequences=False, dropout=0.2, name='LSTM_1')(y)\n",
        "\n",
        "        # Fully connected\n",
        "        y = Dense(7, activation='softmax', name='FC')(y)\n",
        "\n",
        "        # Build final model\n",
        "        model = Model(inputs=input_y, outputs=y)\n",
        "\n",
        "        return model\n",
        "\n",
        "\n",
        "\n",
        "    # Predict speech emotion over time\n",
        "    def predict_emotion_from_file(self, filename, chunk_step=16000, chunk_size=40000, predict_proba=False, sample_rate=16000):\n",
        "\n",
        "        # Read audio file\n",
        "        y, sr = librosa.core.load(filename, sr=sample_rate, offset=0.5)\n",
        "        # Split audio signals into chunks\n",
        "        chunks = self.frame(y.reshape(1, 1, -1), chunk_step, chunk_size)\n",
        "\n",
        "        # Reshape chunks\n",
        "        chunks = chunks.reshape(chunks.shape[1],chunks.shape[-1])\n",
        "\n",
        "        # Z-normalization\n",
        "        y = np.asarray(list(map(zscore, chunks)))\n",
        "\n",
        "        # Compute mel spectrogram\n",
        "        mel_spect = np.asarray(list(map(self.mel_spectrogram, y)))\n",
        "\n",
        "        # Time distributed Framing\n",
        "        mel_spect_ts = self.frame(mel_spect)\n",
        "\n",
        "        # Build X for time distributed CNN\n",
        "        X = mel_spect_ts.reshape(mel_spect_ts.shape[0],\n",
        "                                    mel_spect_ts.shape[1],\n",
        "                                    mel_spect_ts.shape[2],\n",
        "                                    mel_spect_ts.shape[3],\n",
        "                                    1)\n",
        "\n",
        "        # Predict emotion\n",
        "        if predict_proba is True:\n",
        "            predict = self._model.predict(X)\n",
        "        else:\n",
        "            predict = np.argmax(self._model.predict(X), axis=1)\n",
        "            predict = [self._emotion.get(emotion) for emotion in predict]\n",
        "\n",
        "\n",
        "        # Clear Keras session\n",
        "        K.clear_session()\n",
        "\n",
        "        # Predict timestamp\n",
        "        timestamp = np.concatenate([[chunk_size], np.ones((len(predict) - 1)) * chunk_step]).cumsum()\n",
        "        timestamp = np.round(timestamp / sample_rate)\n",
        "\n",
        "        return [predict, timestamp]\n",
        "\n",
        "\n",
        "\n",
        "    #Export emotions\n",
        "    def prediction_to_csv(self, predictions, filename, mode='w'):\n",
        "\n",
        "        # Write emotion in filename\n",
        "        with open(filename, mode) as f:\n",
        "            if mode == 'w':\n",
        "                f.write(\"EMOTIONS\"+'\\n')\n",
        "            for emotion in predictions:\n",
        "                f.write(str(emotion)+'\\n')\n",
        "            f.close()\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rH55CbW6OP17"
      },
      "source": [
        "# Step 6. Load the function that checks which emotion was present the most"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtOAJ1TpnYt9"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        " #Function that finds the most common occuring emotion\n",
        "def find_state_emotion(listOfEmotions):\n",
        "        \n",
        "  count = Counter(listOfEmotions)\n",
        "  max_val = max(count.values())\n",
        "  return sorted(key for key, value in count.items() if value == max_val)\n",
        "        "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVArIyVPOYGC"
      },
      "source": [
        "# Step 7. Run prediction on the loaded files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Th1gbrXyn4mC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d5cf9f3-dd4a-4df2-c796-9315be208109"
      },
      "source": [
        "import json\r\n",
        "import math\r\n",
        "from pydub import AudioSegment\r\n",
        "# Set model sub directory path\r\n",
        "model_sub_dir = os.path.join('models', 'audio.hdf5')\r\n",
        "emotion = {0:'Angry', 1:'Disgust', 2:'Fear', 3:'Happy', 4:'Neutral', 5:'Sad', 6:'Surprise'}\r\n",
        "\r\n",
        "# Initialize SER object\r\n",
        "SER = speechEmotionRecognition(model_sub_dir)\r\n",
        "\r\n",
        "# Create an empty segment emotion list to store emotions\r\n",
        "segmentEmoList = []\r\n",
        "\r\n",
        "# Create an empty final emotion list for tracking emotions through segments\r\n",
        "finalEmoList = []\r\n",
        "\r\n",
        "# List of state flags\r\n",
        "stateFlagList = [0,0,0,0,0,0,0]\r\n",
        "\r\n",
        "# Create an emotion found flag to check if the final emotion was found or not\r\n",
        "isFirstStateFound = False\r\n",
        "\r\n",
        "# Create an empty string for final emotion\r\n",
        "finalEmotion = \"\"\r\n",
        "stateEmotion = \"\"\r\n",
        "\r\n",
        "# Set the name of the audio file\r\n",
        "audio_file_name = os.path.join(\"data\",\"joined_sound_7.wav\")\r\n",
        "\r\n",
        "# Sets the duration of audio\r\n",
        "audio_duration = math.floor(librosa.get_duration(filename=audio_file_name))\r\n",
        "\r\n",
        "# Pritns the duration of the audio\r\n",
        "print(\"The duration of audio is: \" +str(audio_duration))\r\n",
        "# Starting slice and end slice values\r\n",
        "n = 0\r\n",
        "nSpan = 3\r\n",
        "\r\n",
        "# List of sliced segments\r\n",
        "listOfSegNames = []\r\n",
        "\r\n",
        "for i in range(0, (audio_duration + 1) - nSpan):   \r\n",
        "    t1 = n * 1000\r\n",
        "    t2 = (n + nSpan) * 1000\r\n",
        "    \r\n",
        "    # Select audio file to segment\r\n",
        "    oldAudio = AudioSegment.from_wav(audio_file_name)\r\n",
        "\r\n",
        "    # Create a segment of 3 seconds from old audio file\r\n",
        "    newAudio = oldAudio[t1:t2]\r\n",
        "\r\n",
        "    # Save new segment name\r\n",
        "    seg_name = \"working/seg_\" + str(n) + \"_\" +str((n+nSpan)) +\".wav\"\r\n",
        "\r\n",
        "    # Append segment name to a list for later use\r\n",
        "    listOfSegNames.append(seg_name)\r\n",
        "    \r\n",
        "    # Export segment to its own individual file\r\n",
        "    newAudio.export(seg_name, format=\"wav\")\r\n",
        "\r\n",
        "    # Slide the selected second slider by one   \r\n",
        "    n += 1\r\n",
        "\r\n",
        "# Run prediction for each segment\r\n",
        "for k in range(0, len(listOfSegNames)):\r\n",
        "    # Select the segment from the list of saved segment names\r\n",
        "    rec_sub_dir = listOfSegNames[k]\r\n",
        "    \r\n",
        "    # Predict emotion in voice at each time step\r\n",
        "    step = 1 # in sec\r\n",
        "    sample_rate = 16000 # in kHz\r\n",
        "    emotions, timestamp = SER.predict_emotion_from_file(rec_sub_dir, chunk_step=step*sample_rate)\r\n",
        "\r\n",
        "    # Append emotion of the segment to a list\r\n",
        "    segmentEmoList.append(max(set(emotions), key=emotions.count))\r\n",
        "\r\n",
        "\r\n",
        "    # Check states after the initial state\r\n",
        "    if isFirstStateFound == True:\r\n",
        "      # Determine the state of the emotion\r\n",
        "      stateEmotion = max(set(emotions), key=emotions.count)\r\n",
        "\r\n",
        "      # Find the index for the determined emotion\r\n",
        "      stateIndex = list(emotion.keys())[list(emotion.values()).index(stateEmotion)]\r\n",
        "\r\n",
        "      # Increment by 1 for the state that appears\r\n",
        "      stateFlagList[stateIndex] += 1\r\n",
        "\r\n",
        "    # Check if any of the states (Emotions) occurs 3 times\r\n",
        "    if stateFlagList[stateIndex] == 3:\r\n",
        "      # Get the emotion by the index\r\n",
        "      stateEmotion = emotion.get(stateIndex)\r\n",
        "\r\n",
        "      # Append the emotion to the final emotion list\r\n",
        "      finalEmoList.append([stateEmotion])\r\n",
        "\r\n",
        "      # Reset the state (emotion) occurance list to zero\r\n",
        "      stateFlagList = [0,0,0,0,0,0,0]\r\n",
        "\r\n",
        "    # Set the initial state emotion\r\n",
        "    if len(segmentEmoList) > 2 and isFirstStateFound == False:\r\n",
        "      # Call function to determine emotion\r\n",
        "      firstState = find_state_emotion(segmentEmoList)\r\n",
        "      if len(firstState) == 1:\r\n",
        "        # Add the segment emotion to the list\r\n",
        "        finalEmoList.append(firstState)\r\n",
        "        isFirstStateFound = True\r\n",
        "        #del segmentEmoList[:]\r\n",
        "\r\n",
        "# Prints for debugging\r\n",
        "print(segmentEmoList)\r\n",
        "print(finalEmoList)\r\n",
        "\r\n",
        "# Create an empty list to store unhashedList\r\n",
        "unhashedList = []\r\n",
        "\r\n",
        "# Unhashes a list for readability\r\n",
        "for item in finalEmoList:\r\n",
        "  unhashedList.append(item[0])\r\n",
        "\r\n",
        "# Check if there is a majority for the segments\r\n",
        "return_emotion = find_state_emotion(unhashedList)\r\n",
        "print(return_emotion)\r\n",
        "\r\n",
        "# If there is no majority therefore the emotion is neutral\r\n",
        "if len(return_emotion) != 1:\r\n",
        "  print(\"Majority doesn't win\")\r\n",
        "  print(\"The emotion is: Neutral\")\r\n",
        "else:\r\n",
        "  # If there is a majority then print the emotion\r\n",
        "  print(\"Majority wins\")\r\n",
        "  print(\"The emotion is: \" + str(return_emotion[0]))\r\n",
        "\r\n",
        "# Code for removing the segments\r\n",
        "for segment in listOfSegNames:\r\n",
        "  !rm $segment\r\n",
        "print(\"Previous segments removed\")\r\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The duration of audio is: 76\n",
            "['Angry', 'Angry', 'Disgust', 'Disgust', 'Angry', 'Angry', 'Angry', 'Angry', 'Disgust', 'Angry', 'Angry', 'Happy', 'Happy', 'Neutral', 'Neutral', 'Fear', 'Neutral', 'Fear', 'Fear', 'Neutral', 'Disgust', 'Angry', 'Happy', 'Disgust', 'Disgust', 'Sad', 'Disgust', 'Neutral', 'Disgust', 'Disgust', 'Disgust', 'Disgust', 'Disgust', 'Neutral', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Angry', 'Happy', 'Happy', 'Happy', 'Happy', 'Happy', 'Disgust', 'Surprise', 'Happy', 'Happy', 'Fear', 'Sad', 'Sad', 'Sad', 'Sad', 'Sad', 'Sad', 'Sad', 'Sad', 'Sad', 'Sad', 'Neutral', 'Sad', 'Sad', 'Sad', 'Sad', 'Sad', 'Neutral', 'Fear', 'Surprise', 'Surprise', 'Fear', 'Surprise', 'Surprise']\n",
            "[['Angry'], ['Angry'], ['Angry'], ['Neutral'], ['Disgust'], ['Disgust'], ['Disgust'], ['Happy'], ['Happy'], ['Happy'], ['Happy'], ['Sad'], ['Sad'], ['Sad'], ['Sad'], ['Sad'], ['Surprise']]\n",
            "['Sad']\n",
            "Majority wins\n",
            "The emotion is: Sad\n",
            "Previous segments removed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw2vpcfU0udk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "fd31b012-9006-4f05-b0d6-a8f6228edab7"
      },
      "source": [
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "# 0:'Angry', 1:'Disgust', 2:'Fear', 3:'Happy', 4:'Neutral', 5:'Sad', 6:'Surprise'\r\n",
        "\r\n",
        "\r\n",
        "a = [3]\r\n",
        "b = [5]\r\n",
        "c = [4]\r\n",
        "d = [6]\r\n",
        "e = [2]\r\n",
        "f = [4]\r\n",
        "g = [3]\r\n",
        "\r\n",
        "# {'Angry' : a,'Disgust' : b, 'Fear' : c, 'Happy': d, 'Neutral': e, 'Sad': f, 'Surprise': g \r\n",
        "\r\n",
        "df = pd.DataFrame({'Angry': a}, ignore_index=True)\r\n",
        "df.append({'Disgust': b})\r\n",
        "ax = df.plot.barh(stacked=True);\r\n",
        "\r\n",
        "ax.figure.set_size_inches(10,6)\r\n",
        "ax.set_xlabel('Time (in sec)', fontsize=18)\r\n",
        "ax.set_ylabel('States', fontsize=18)\r\n",
        "ax.set_yticklabels([])\r\n",
        "\r\n",
        "ax.set_title(audio_file_name)\r\n",
        "ax.legend(loc='upper left')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-ea44d6245fe4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# {'Angry' : a,'Disgust' : b, 'Fear' : c, 'Happy': d, 'Neutral': e, 'Sad': f, 'Surprise': g\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Angry'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Disgust'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstacked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'ignore_index'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpSqmaR6iE8h"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}